# Metacognitive Symbolic Distillation Framework for Multi-choice Machine Reading Comprehension

This repository implements the Metacognitive Symbolic Distillation Framework for improving the performance of small models on multi-choice machine reading comprehension (MMRC) tasks by leveraging the reasoning abilities of large language models (LLMs).

## Introduction

Symbolic knowledge distillation is a powerful technique for transferring the reasoning capabilities of large language models to smaller, more efficient models. However, traditional distillation methods in MMRC tasks often focus only on the rationales of correct options, neglecting the educational value of understanding why incorrect options are wrong. Drawing inspiration from human education, where metacognition emphasizes identifying errors to enhance understanding, we propose a novel framework that incorporates metacognitive strategies into symbolic distillation. This approach not only improves the performance of small models but also enhances their interpretability.

For more details, please refer to our [paper](https://doi.org/10.1016/j.knosys.2025.113130).

## Abstract

Symbolic knowledge distillation can transfer the reasoning abilities of large language models (LLMs) effectively to smaller models. However, in the context of multi-choice machine reading comprehension (MMRC), traditional distillation methods focus primarily on learning from the rationales of the correct options generated by the large teacher model, overlooking the educational significance of reasoning behind incorrect options. In human education, metacognition emphasizes the importance of actively identifying errors, enhancing the overall understanding. Inspired by this approach, we propose an innovative framework that incorporates metacognition into symbolic distillation. Initially, we prompt the teacher LLM to generate rationales for all options in the MMRC dataset. Subsequently, the small student model is fine-tuned using these rationales, including those for incorrect options. Our experiments on two MMRC datasets demonstrate that this framework improves the performance of the small student model significantly compared to standard fine-tuned and distilled models. We further find that when the student model is sufficiently large, upgrading the teacher model could yield further improvements. However, the effectiveness of our framework is constrained by the performance of the teacher model on more complex MMRC tasks.

## Code Workflow

The code in this repository follows a three-step workflow:

1. **Student Training Data Generation**  
   - **File:** `student_training_data_generation.py`  
   - **Description:** This script uses the teacher LLM to generate rationales for all options in the MMRC dataset, including both correct and incorrect options. This step is crucial for incorporating metacognitive strategies into the distillation process.

2. **Student Model Training**  
   - **File:** `student_training.py`  
   - **Description:** The generated rationales are used to fine-tune the small student model. This step ensures that the student model learns not only the correct answers but also the reasoning behind incorrect options, enhancing its overall performance and interpretability.

3. **Student Model Inference**  
   - **File:** `student_infer.py`  
   - **Description:** After training, the student model can be used for inference on new MMRC tasks. This script demonstrates how to perform metacognitive reasoning using the trained student model.
